{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fc2bdc5e",
      "metadata": {
        "id": "fc2bdc5e"
      },
      "source": [
        "# Graph Neural Networks (GNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "829c0913",
      "metadata": {
        "id": "829c0913"
      },
      "source": [
        "## Quelle der Daten\n",
        "\n",
        "https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database?resource=download (zuletzt aufgerufen 01/2024)\n",
        "    \n",
        "M.E.H. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M.A. Kadir, Z.B. Mahbub, K.R. Islam, M.S. Khan, A. Iqbal, N. Al-Emadi, M.B.I. Reaz, M. T. Islam, “Can AI help in screening Viral and COVID-19 pneumonia?” IEEE Access, Vol. 8, 2020, pp. 132665 - 132676.\n",
        "\n",
        "Rahman, T., Khandakar, A., Qiblawey, Y., Tahir, A., Kiranyaz, S., Kashem, S.B.A., Islam, M.T., Maadeed, S.A., Zughaier, S.M., Khan, M.S. and Chowdhury, M.E., 2020. Exploring the Effect of Image Enhancement Techniques on COVID-19 Detection using Chest X-ray Images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3a84e0f",
      "metadata": {
        "id": "e3a84e0f"
      },
      "source": [
        "## Installation der Bibliotheken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8789a50e",
      "metadata": {
        "id": "8789a50e"
      },
      "outputs": [],
      "source": [
        "# Bibliotheken importieren, die für das Laden, Vorverarbeiten und Modellieren der Daten benötigt werden.\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Model, layers\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "import keras\n",
        "\n",
        "import requests\n",
        "\n",
        "import tempfile\n",
        "\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ed883e2",
      "metadata": {
        "id": "8ed883e2"
      },
      "source": [
        "## Download der Daten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b76629",
      "metadata": {
        "id": "b6b76629"
      },
      "outputs": [],
      "source": [
        "# URL des Datensatzes festlegen und temporäres Verzeichnis für den Download erstellen.\n",
        "# load dataset from online resource, given here: https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database\n",
        "ds_url = \"https://drive.usercontent.google.com/download?id=1bum9Sehb3AzUMHLhBMuowPKyr_PCrB3a&export=download&confirm=1\"\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "print(f\"Temporary file-directory for saving dataset: '{temp_dir}'\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d82fc1",
      "metadata": {
        "id": "01d82fc1"
      },
      "outputs": [],
      "source": [
        "# for downloading from google-drive, use method described\n",
        "# elsewhere (https://stackoverflow.com/a/39225272)\n",
        "# with some modifications\n",
        "\n",
        "def download_file_from_google_drive(URL, destination_dir):\n",
        "    # Funktion zum Herunterladen einer Datei von Google Drive\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, stream=True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = {\"confirm\": token}\n",
        "        response = session.get(URL, params=params, stream=True)\n",
        "\n",
        "    save_response_content(response, destination_dir)\n",
        "\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    # Funktion zum Abrufen des Bestätigungstokens für den Download\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith(\"download_warning\"):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def save_response_content(response, destination_dir):\n",
        "    # Funktion zum Speichern des Dateiinhaltes\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination_dir + \"/data.zip\", \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:  # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "# Die Datei von Google Drive herunterladen\n",
        "download_file_from_google_drive(ds_url, temp_dir)\n",
        "\n",
        "print(\"Folder structure inside 'tempdir':\\n\")\n",
        "print(os.listdir(temp_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa6a86fe",
      "metadata": {
        "id": "fa6a86fe"
      },
      "outputs": [],
      "source": [
        "# Entpacken der heruntergeladenen Zip-Datei\n",
        "shutil.unpack_archive(filename=temp_dir + \"/data.zip\", extract_dir=temp_dir)\n",
        "print(\"Folder structure inside 'tempdir':\\n\")\n",
        "print(os.listdir(temp_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69bcb19f",
      "metadata": {
        "id": "69bcb19f"
      },
      "source": [
        "## Einlesen und Präprozessierung der Daten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c3d0d0",
      "metadata": {
        "id": "c0c3d0d0"
      },
      "outputs": [],
      "source": [
        "# Pfade zu den Bilderverzeichnissen festlegen und Anzahl der Bilder ausgeben\n",
        "main_path = temp_dir + \"/COVID-19_Radiography_Dataset\"\n",
        "print(os.listdir(main_path))\n",
        "\n",
        "covid_dir = os.path.join(main_path, \"COVID/images\")\n",
        "normal_dir = os.path.join(main_path, \"Normal/images\")\n",
        "\n",
        "print(\"Anzahl Bilder mit COVID:\", len(os.listdir(covid_dir)))\n",
        "print(\"Anzahl normaler Bilder:\", len(os.listdir(normal_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfb2b59d",
      "metadata": {
        "id": "bfb2b59d"
      },
      "outputs": [],
      "source": [
        "# Beispielbild laden und anzeigen\n",
        "example_image = cv2.imread(os.path.join(covid_dir, \"COVID-1.png\"))\n",
        "\n",
        "plt.imshow(example_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08cbfd1f",
      "metadata": {
        "id": "08cbfd1f"
      },
      "outputs": [],
      "source": [
        "# Form des Beispielbildes ausgeben\n",
        "print(example_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b7026b",
      "metadata": {
        "id": "51b7026b"
      },
      "outputs": [],
      "source": [
        "# Funktion zum Laden und Vorverarbeiten von Bildern aus einem Verzeichnis\n",
        "def loadImages(dir, size, label):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for i in range(len(size)):\n",
        "    img_path = dir + \"/\" + size[i]\n",
        "    img = cv2.imread(img_path)\n",
        "    img = img / 255.0\n",
        "    img = cv2.resize(img, (100, 100))\n",
        "    images.append(img)\n",
        "    labels.append(label)\n",
        "\n",
        "  images = np.asarray(images)\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e11c35",
      "metadata": {
        "id": "d7e11c35"
      },
      "outputs": [],
      "source": [
        "# Laden und Beschriften von COVID-Bildern (10% des Datensatzes)\n",
        "# (kann bei Bedarf / je nach Verfügbarkeit der Ressourcen angepasst werden)\n",
        "covid_images, covid_labels = loadImages(covid_dir, os.listdir(covid_dir)[:int(0.1*len(os.listdir(covid_dir)))], 1)\n",
        "print(\"Covid cases:\\n\")\n",
        "print(len(covid_images), len(covid_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c81178",
      "metadata": {
        "id": "f7c81178"
      },
      "outputs": [],
      "source": [
        "# Ausgabe der ersten 10 Covid-Labels\n",
        "print(covid_labels[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Laden und Beschriften von normalen Bildern (10% des Datensatzes)\n",
        "# (kann bei Bedarf / je nach Verfügbarkeit der Ressourcen angepasst werden)\n",
        "normal_images, normal_labels = loadImages(normal_dir, os.listdir(normal_dir)[:int(0.1*len(os.listdir(normal_dir)))], 0)\n",
        "print(\"Normal cases:\\n\")\n",
        "print(len(normal_images), len(normal_labels))"
      ],
      "metadata": {
        "id": "O5hF0LKcTO8N"
      },
      "id": "O5hF0LKcTO8N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ausgabe der ersten 10 Labels von normalen Fällen\n",
        "print(normal_labels[0:10])"
      ],
      "metadata": {
        "id": "FaltyUsuTPFM"
      },
      "id": "FaltyUsuTPFM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2285ae83",
      "metadata": {
        "id": "2285ae83"
      },
      "source": [
        "## Aufteilung der Daten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd576c55",
      "metadata": {
        "id": "cd576c55"
      },
      "outputs": [],
      "source": [
        "# Kombinieren der COVID- und normalen Bilddaten und Labels\n",
        "x = np.r_[covid_images, normal_images]\n",
        "\n",
        "y = np.r_[covid_labels, normal_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2a75b33",
      "metadata": {
        "id": "a2a75b33"
      },
      "outputs": [],
      "source": [
        "# Aufteilen der Daten in Trainings- und Testsets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ec79c85",
      "metadata": {
        "id": "1ec79c85"
      },
      "source": [
        "## Umwandlung der Bilder in Graphen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0b0089",
      "metadata": {
        "id": "2c0b0089"
      },
      "outputs": [],
      "source": [
        "def image_to_graph(image):\n",
        "  # Die Form des Bildes abrufen (Höhe, Breite, Kanäle)\n",
        "  h, w, c = image.shape\n",
        "\n",
        "  # Indizes für jeden Pixel erstellen und in eine 2D-Struktur umwandeln\n",
        "  node_indices = np.arange(h * w).reshape((h, w))\n",
        "\n",
        "  # Kanten für benachbarte Pixel in horizontaler Richtung (rechts und links) erstellen\n",
        "  edges_r = np.stack((node_indices[:, :-1].reshape((-1)), node_indices[:, 1:].reshape((-1))), axis = 0)\n",
        "  edges_l = np.stack((node_indices[:, 1:].reshape((-1)), node_indices[:, :-1].reshape((-1))), axis = 0)\n",
        "  # Kanten für benachbarte Pixel in vertikaler Richtung (unten und oben) erstellen\n",
        "  edges_d = np.stack((node_indices[:-1, :].reshape((-1)), node_indices[1:, :].reshape((-1))), axis = 0)\n",
        "  edges_u = np.stack((node_indices[1:, :].reshape((-1)), node_indices[:-1, :].reshape((-1))), axis = 0)\n",
        "\n",
        "  # Alle Kanten zusammenführen\n",
        "  edges = np.concatenate((edges_r, edges_l, edges_d, edges_u), axis = 1).astype(np.int32)\n",
        "  # Kanten in einen TensorFlow Tensor umwandeln\n",
        "  edges = tf.convert_to_tensor(edges)\n",
        "\n",
        "  # Gewichte für jede Kante erstellen (hier: alle Gewichte sind 1)\n",
        "  edge_weights = tf.ones(shape = edges.shape[1])\n",
        "\n",
        "  # Pixelwerte als Knotenmerkmale in einen TensorFlow Tensor umwandeln\n",
        "  node_features = tf.convert_to_tensor(image.reshape((-1, 3)).astype(np.float32))\n",
        "\n",
        "  # Graphinformationen (Knotenmerkmale, Kanten, Kantengewichte) zurückgeben\n",
        "  graph_info = (node_features, edges, edge_weights)\n",
        "\n",
        "  return graph_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daeddb3c",
      "metadata": {
        "id": "daeddb3c"
      },
      "outputs": [],
      "source": [
        "# Bilder in Graphen umwandeln\n",
        "train_graphs = [image_to_graph(img) for img in x_train]\n",
        "\n",
        "test_graphs = [image_to_graph(img) for img in x_test]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Den ersten Graphen im Trainingsdatensatz ausgeben (zur Überprüfung der Struktur)\n",
        "train_graphs[0]"
      ],
      "metadata": {
        "id": "5X-m8T7GTgf0"
      },
      "id": "5X-m8T7GTgf0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "733e5889",
      "metadata": {
        "id": "733e5889"
      },
      "source": [
        "## GNN-Architektur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f889de96",
      "metadata": {
        "id": "f889de96"
      },
      "outputs": [],
      "source": [
        "def create_fcnn(hidden_units):\n",
        "    # Eine Liste für die Schichten des Fully Connected Neural Network (FCNN) erstellen\n",
        "    fcnn_layers = []\n",
        "\n",
        "    # Schichten hinzufügen: Batch-Normalisierung und Dense-Schicht mit ReLU-Aktivierung\n",
        "    for units in hidden_units:\n",
        "        fcnn_layers.append(layers.BatchNormalization())\n",
        "        fcnn_layers.append(layers.Dense(units, activation = tf.nn.relu))\n",
        "\n",
        "    # Das FCNN als Keras Sequential Modell zurückgeben\n",
        "    return keras.Sequential(fcnn_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9537e627",
      "metadata": {
        "id": "9537e627"
      },
      "outputs": [],
      "source": [
        "class GraphConvLayer(layers.Layer):\n",
        "    # Initialisierung der Graph Convolutional Layer\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_units,\n",
        "        aggregation_type = \"mean\",\n",
        "        combination_type = \"concat\",\n",
        "        normalize = False,\n",
        "        *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        # Attribute für Aggregations-, Kombinations- und Normalisierungstyp festlegen\n",
        "        self.aggregation_type = aggregation_type\n",
        "        self.combination_type = combination_type\n",
        "        self.normalize = normalize\n",
        "\n",
        "        # FCNN für die Vorverarbeitung der Nachrichten erstellen\n",
        "        self.fcnn_prepare = create_fcnn(hidden_units)\n",
        "        # FCNN für die Aktualisierung der Knoten-Embeddings erstellen\n",
        "        self.update_fn = create_fcnn(hidden_units)\n",
        "\n",
        "    # Methode zur Vorverarbeitung der Knotenrepräsentationen\n",
        "    def prepare(self, node_repesentations, weights = None):\n",
        "        b, num_edges, embedding_dim = node_repesentations.shape\n",
        "        # Nachrichten mit dem Vorverarbeitungs-FCNN berechnen\n",
        "        messages = self.fcnn_prepare(node_repesentations)\n",
        "        # Optional: Nachrichten mit Kantengewichten multiplizieren\n",
        "        if weights is not None:\n",
        "            messages = messages * tf.reshape(weights, (1, num_edges, 1))\n",
        "\n",
        "        return messages\n",
        "\n",
        "    # Methode zur Aggregation der Nachrichten von Nachbarknoten\n",
        "    def aggregate(self, node_indices, neighbour_messages, node_repesentations):\n",
        "        num_nodes = node_repesentations.shape[1]\n",
        "        b, num_edges, embedding_dim = neighbour_messages.shape\n",
        "\n",
        "        # Nachrichten für die Aggregation umformen\n",
        "        neighbour_messages = tf.reshape(tf.transpose(neighbour_messages, (1, 0, 2)), (num_edges, -1))\n",
        "\n",
        "        # Nachrichten basierend auf den Knotenindizes aggregieren (hier: Mittelwert)\n",
        "        aggregated_message = tf.math.unsorted_segment_mean(neighbour_messages, node_indices, num_segments = num_nodes)\n",
        "        # Aggregierte Nachrichten in die ursprüngliche Form zurückformen\n",
        "        aggregated_message = tf.reshape(aggregated_message, (num_nodes, -1, embedding_dim))\n",
        "        aggregated_message = tf.transpose(aggregated_message, (1, 0, 2))\n",
        "\n",
        "        return aggregated_message\n",
        "\n",
        "    # Methode zur Aktualisierung der Knotenrepräsentationen\n",
        "    def update(self, node_repesentations, aggregated_messages):\n",
        "        # Knotenrepräsentationen und aggregierte Nachrichten zusammenführen\n",
        "        h = tf.concat([node_repesentations, aggregated_messages], axis = -1)\n",
        "        # Knoten-Embeddings mit der Update-Funktion berechnen\n",
        "        node_embeddings = self.update_fn(h)\n",
        "\n",
        "        return node_embeddings\n",
        "\n",
        "    # Call-Methode für die Ausführung der Graph Convolutional Layer\n",
        "    def call(self, inputs):\n",
        "        # Eingaben entpacken: Knotenrepräsentationen, Kanten, Kantengewichte\n",
        "        node_repesentations, edges, edge_weights = inputs\n",
        "        # Knoten- und Nachbarknotenindizes extrahieren\n",
        "        node_indices, neighbour_indices = edges[0], edges[1]\n",
        "        # Repräsentationen der Nachbarknoten sammeln\n",
        "        neighbour_repesentations = tf.gather(node_repesentations, neighbour_indices, batch_dims=0, axis=1)\n",
        "\n",
        "        # Nachrichten von Nachbarn vorbereiten\n",
        "        neighbour_messages = self.prepare(neighbour_repesentations, edge_weights)\n",
        "        # Nachrichten aggregieren\n",
        "        aggregated_messages = self.aggregate(node_indices, neighbour_messages, node_repesentations)\n",
        "\n",
        "        # Knotenrepräsentationen aktualisieren und zurückgeben\n",
        "        return self.update(node_repesentations, aggregated_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eeedcfa",
      "metadata": {
        "id": "5eeedcfa"
      },
      "outputs": [],
      "source": [
        "class GNNGraphClassifier(tf.keras.Model):\n",
        "    # Initialisierung des GNN Graph Classifiers\n",
        "    def __init__(\n",
        "        self,\n",
        "        graph_info,\n",
        "        hidden_units,\n",
        "        aggregation_type = \"sum\",\n",
        "        combination_type = \"concat\",\n",
        "        normalize = True,\n",
        "        *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        # Graphinformationen extrahieren\n",
        "        node_features, edges, edge_weights = graph_info\n",
        "        # Graphinformationen als Attribute speichern\n",
        "        self.node_features = node_features\n",
        "        self.edges = edges\n",
        "        self.edge_weights = edge_weights\n",
        "        # Kantengewichte normalisieren\n",
        "        self.edge_weights = self.edge_weights / tf.math.reduce_sum(self.edge_weights)\n",
        "\n",
        "        # FCNN für die Vorverarbeitung der Knotenmerkmale erstellen\n",
        "        self.preprocess = create_fcnn(hidden_units)\n",
        "        # Erste Graph Convolutional Layer erstellen\n",
        "        self.conv1 = GraphConvLayer(hidden_units, aggregation_type, combination_type, normalize)\n",
        "        # Zweite Graph Convolutional Layer erstellen\n",
        "        self.conv2 = GraphConvLayer(hidden_units, aggregation_type, combination_type, normalize)\n",
        "        # FCNN für die Nachverarbeitung der Knoten-Embeddings erstellen\n",
        "        self.postprocess = create_fcnn(hidden_units)\n",
        "        # Dense-Schicht zur Berechnung der Sigmoid-Ausgabe (Klassifizierung) erstellen\n",
        "        self.compute_sigmoid = layers.Dense(units = 1)\n",
        "\n",
        "    # Call-Methode für die Ausführung des GNN Graph Classifiers\n",
        "    def call(self, node_features):\n",
        "        # Knotenmerkmale vorverarbeiten\n",
        "        x = self.preprocess(node_features)\n",
        "        # Erste Graph Convolution anwenden und Residual Connection hinzufügen\n",
        "        x1 = self.conv1((x, self.edges, self.edge_weights))\n",
        "        x = x1 + x\n",
        "        # Zweite Graph Convolution anwenden und Residual Connection hinzufügen\n",
        "        x2 = self.conv2((x, self.edges, self.edge_weights))\n",
        "        x = x2 + x\n",
        "        # Knoten-Embeddings nachverarbeiten\n",
        "        x = self.postprocess(x)\n",
        "\n",
        "        # Graph-Embedding durch Mittelwertbildung über die Knoten-Embeddings berechnen\n",
        "        graph_embedding = tf.reduce_mean(x, axis = 1, keepdims = False)\n",
        "\n",
        "        # Sigmoid-Ausgabe für die Klassifizierung berechnen und zurückgeben\n",
        "        return self.compute_sigmoid(graph_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a226e764",
      "metadata": {
        "id": "a226e764"
      },
      "outputs": [],
      "source": [
        "# Instanz des GNNGraphClassifier Modells erstellen\n",
        "# Hier wird der erste Graph aus den Trainingsdaten als Beispiel für die Graphstruktur verwendet\n",
        "gnn_model = GNNGraphClassifier(\n",
        "    graph_info = train_graphs[0],\n",
        "    hidden_units = [32]) # Anzahl der Einheiten in den versteckten Schichten festlegen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf2788be",
      "metadata": {
        "id": "cf2788be"
      },
      "source": [
        "## Modelltraining und -evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4929338",
      "metadata": {
        "id": "f4929338"
      },
      "outputs": [],
      "source": [
        "# Das GNN-Modell kompilieren\n",
        "gnn_model.compile(optimizer = \"adam\", # Optimizer festlegen (hier: Adam)\n",
        "              loss = \"binary_crossentropy\", # Verlustfunktion festlegen (hier: Binary Crossentropy für binäre Klassifizierung)\n",
        "              metrics = [\"accuracy\"]) # Metriken für die Evaluation festlegen (hier: Genauigkeit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c43ff9ca",
      "metadata": {
        "id": "c43ff9ca"
      },
      "outputs": [],
      "source": [
        "# Trainingsdaten in ein NumPy-Array umwandeln (nur die Knotenmerkmale)\n",
        "x_train = np.array([tg[0] for tg in train_graphs], dtype = np.float32)\n",
        "\n",
        "# Das GNN-Modell trainieren\n",
        "gnn_model.fit(x_train, y_train, epochs = 5, batch_size = 32) # Anzahl der Epochen und Batch-Größe festlegen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df56391",
      "metadata": {
        "id": "5df56391"
      },
      "outputs": [],
      "source": [
        "# Testdaten in ein NumPy-Array umwandeln (nur die Knotenmerkmale)\n",
        "x_test = np.array([tg[0] for tg in test_graphs], dtype = np.float32),\n",
        "\n",
        "# Das trainierte GNN-Modell auf den Testdaten evaluieren und die Ergebnisse ausgeben\n",
        "eval_results = gnn_model.evaluate(x_test, y_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_results)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}